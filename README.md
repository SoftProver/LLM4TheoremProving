## Surveys

1. **A Survey on Deep Learning for Theorem Proving** `COLM 2024` [[paper]](https://arxiv.org/pdf/2404.09939)

   *Zhaoyu Li, Jialiang Sun, Logan Murphy, Qidong Su, Zenan Li, Xian Zhang, Kaiyu Yang, and Xujie Si* 



## Math Datasets and Benchmark
1. **Lean Workbook: A large-scale Lean problem set formalized from natural language math problems** `NeurIPS 2025 dataset and benchmark track` [[paper]](https://arxiv.org/abs/2406.03847)
  
   *Huaiyuan Ying, Zijian Wu, Yihan Geng, Jiayu Wang, Dahua Lin, Kai Chen*

2. **CLEVER: Curated Lean Verified Code Generation Benchmark** `arXiv 2025` [[paper]](https://arxiv.org/abs/2505.13938)

   *Amitayush Thakur, Jasper Lee, George Tsoukalas, Meghana Sistla, Matthew Zhao, Stefan Zetzsche, Greg Durrett, Yisong Yue, Swarat Chaudhuri*

3. **VERINA: Benchmarking Verifiable Code Generation** `arXiv 2025` [[paper]](https://arxiv.org/abs/2505.23135)

   *Zhe Ye, Zhengxu Yan, Jingxuan He, Timothe Kasriel, Kaiyu Yang, Dawn Song*

## Data Synthesis and Self-Evolution
1. **STP: Self-play LLM Theorem Provers with Iterative Conjecturing and Proving**
`ICML 2025` [[paper]](https://arxiv.org/abs/2502.00212)

   *Kefan Dong, Tengyu Ma*


## Autoformalization

1. **Autoformalization in the Era of Large Language Models: A Survey** `arXiv 2025` [[paper]](https://arxiv.org/pdf/2505.23486)

   *Ke Weng, Lun Du, Sirui Li, Wangyue Lu, Haozhe Sun, Hengyu Liu, Tiancheng Zhang*

2. **nl2spec: Interactively Translating Unstructured Natural Language to Temporal Logics with Large Language Models** `CAV 2023` [[paper]](https://arxiv.org/abs/2303.04864)

   *Matthias Cosler, Christopher Hahn, Daniel Mendoza, Frederik Schmitt, Caroline Trippel*

3. **Enchanting Program Specification Synthesis by Large Language Models using Static Analysis and Program Verification** `CAV 2024` [[paper]](https://arxiv.org/abs/2404.00762)

   *Cheng Wen, Jialun Cao, Jie Su, Zhiwu Xu, Shengchao Qin, Mengda He, Haokun Li, Shing-Chi Cheung, Cong Tian*

## Premise Selection

1. **LeanDojo: Theorem Proving with Retrieval-Augmented Language Models** `NeurIPS 2023 dataset and benchmark track` [[paper]](https://arxiv.org/abs/2306.15626)

   *Kaiyu Yang, Aidan M. Swope, Alex Gu, Rahul Chalamala, Peiyang Song, Shixing Yu, Saad Godil, Ryan Prenger, Anima Anandkumar*

2. **DeepMath - Deep Sequence Models for Premise Selection** `NeurIPS 2016` [[paper]](https://arxiv.org/abs/1606.04442)

   *Alex A. Alemi, Francois Chollet, Niklas Een, Geoffrey Irving, Christian Szegedy, Josef Urban*

3. **HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving** `ICLR 2017` [[paper]](https://arxiv.org/abs/1703.00426)

   *Cezary Kaliszyk, François Chollet, Christian Szegedy*

4. **Premise Selection for Theorem Proving by Deep Graph Embedding** `NeurIPS 2017` [[paper]](https://arxiv.org/abs/1709.09994)

   *Mingzhe Wang, Yihe Tang, Jian Wang, Jia Deng*

5. **Graph2Tac: Online Representation Learning of Formal Math Concepts** `ICML 2024` [[paper]](https://arxiv.org/abs/2401.02949)

   *Lasse Blaauwbroek, Miroslav Olšák, Jason Rute, Fidel Ivan Schaposnik Massolo, Jelle Piepenbrock, Vasily Pestun*

## Proof Generation
<!-- hammer-like -->
1. **Lean-SMT: An SMT tactic for discharging proof goals in Lean** `CAV 2025` [[paper]](https://arxiv.org/abs/2505.15796)

   *Abdalrhman Mohamed, Tomaz Mascarenhas, Harun Khan, Haniel Barbosa, Andrew Reynolds, Yicheng Qian, Cesare Tinelli, and Clark Barrett*

2. **Lean-auto: An Interface between Lean 4 and Automated Theorem Provers** `CAV 2025` [[paper]](https://arxiv.org/abs/2505.14929)

   *Yicheng Qian, Joshua Clune, Clark Barrett, Jeremy Avigad*

<!-- tree-search -->
3. **MPS-Prover: Advancing Stepwise Theorem Proving by Multi-Perspective Search and Data Curation** `arXiv 2025` [[paper]](https://arxiv.org/abs/2505.10962)

   *Zhenwen Liang, Linfeng Song, Yang Li, Tao Yang, Feng Zhang, Haitao Mi, Dong Yu*

<!-- draft-sketch-prove -->
4. **Draft, Sketch, and Prove: Guiding Formal Theorem Provers with Informal Proofs** `ICLR 2023` [[paper]](https://arxiv.org/abs/2210.12283)

   *Albert Q. Jiang, Sean Welleck, Jin Peng Zhou, Wenda Li, Jiacheng Liu, Mateja Jamnik, Timothée Lacroix, Yuhuai Wu, Guillaume Lample*

5. **Efficient Neural Theorem Proving via Fine-grained Proof Structure Analysis** `ICML 2025` [[paper]](https://arxiv.org/abs/2501.18310)

   *Haoxiong Liu, Jiacheng Sun, Zhenguo Li, Andrew C Yao*

<!-- whole-proof-gen -->

6. **Baldur: Whole-Proof Generation and Repair with Large Language Models** `ESEC/FSE 2023` [[paper]](https://arxiv.org/abs/2303.04910)

   *Emily First, Markus N. Rabe, Talia Ringer, Yuriy Brun*

7. **Neural Theorem Proving: Generating and Structuring Proofs for Formal Verification** `NeSy 2025` [[paper]](https://arxiv.org/abs/2504.17017)

   *Balaji Rao, William Eiers, Carlo Lipizzi*

8. **StepFun-Prover Preview: Let’s Think and Verify Step by Step** `arXiv 2025` [[paper]](https://arxiv.org/pdf/2507.20199)

   *Shijie Shang, Ruosi Wan, Yue Peng, Yutong Wu, Xiong-hui Chen, Jie Yan, Xiangyu Zhang*


## Proof Engineering

1. **Why the Proof Fails in Different Versions of Theorem Provers: An Empirical Study of Compatibility Issues in Isabelle** `FSE 2025` [[https://dl.acm.org/doi/10.1145/3715787]]

   *Xiaokun Luan, David Sanan, Zhe Hou, Qiyuan Xu, Chengwei Liu, Yufan Cai, Yang Liu, Meng Sun*
